"""
çŸ¥è¯†æ–‡æ¡£ç»“æ„å¥‘çº¦æµ‹è¯• (TDD RED Phase)

éªŒè¯ Core+Appendix è¾“å‡ºç»“æ„å¥‘çº¦ï¼š
- é»˜è®¤æ¨¡å¼ï¼šç´§å‡‘æ ¸å¿ƒå†…å®¹ + å®Œæ•´é™„å½•
- é—ç•™æ¨¡å¼ï¼šä¿æŒå‘åå…¼å®¹æ€§
"""

import pytest
from analyzer.models import KnowledgeDocument


@pytest.fixture
def minimal_knowledge_doc():
    """æœ€å°åŒ–çŸ¥è¯†æ–‡æ¡£ fixtureï¼ˆç”¨äºæµ‹è¯•ç»“æ„å¥‘çº¦ï¼‰"""
    return KnowledgeDocument(
        title="æµ‹è¯•æ ‡é¢˜ï¼šæ·±åº¦å­¦ä¹ åŸºç¡€",
        one_sentence_summary="è¿™æ˜¯ä¸€å¥è¯æ€»ç»“ï¼Œç”¨äºæµ‹è¯•æ–‡æ¡£ç»“æ„ã€‚",
        key_takeaways=[
            "å…³é”®ç»“è®º1ï¼šæ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡æ•°æ®",
            "å…³é”®ç»“è®º2ï¼šåå‘ä¼ æ’­æ˜¯æ ¸å¿ƒç®—æ³•",
        ],
        deep_dive=[
            {
                "chapter_title": "ç¥ç»ç½‘ç»œåŸºç¡€",
                "chapter_summary": "æœ¬ç« ä»‹ç»ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ¦‚å¿µå’Œç»“æ„ã€‚",
                "sections": [
                    {
                        "topic": "æ„ŸçŸ¥æœºæ¨¡å‹",
                        "explanation": "æ„ŸçŸ¥æœºæ˜¯æœ€ç®€å•çš„ç¥ç»ç½‘ç»œå•å…ƒï¼Œç”±è¾“å…¥å±‚å’Œè¾“å‡ºå±‚ç»„æˆã€‚",
                        "example": "è¾“å…¥ï¼š[0.5, 0.3] â†’ æƒé‡ï¼š[0.2, 0.8] â†’ è¾“å‡ºï¼š0.5*0.2 + 0.3*0.8 = 0.34",
                        "code": "def perceptron(x, w):\n    return sum(xi * wi for xi, wi in zip(x, w))",
                        "challenge": [
                            "å¦‚æœè¾“å…¥æ˜¯è´Ÿæ•°ï¼Œæ„ŸçŸ¥æœºä¼šå¦‚ä½•å¤„ç†ï¼Ÿ",
                            "ä¸ºä»€ä¹ˆéœ€è¦æ¿€æ´»å‡½æ•°ï¼Ÿ",
                        ],
                        "self_check": [
                            {"q": "æ„ŸçŸ¥æœºæœ‰å‡ å±‚ï¼Ÿ", "a": "ä¸¤å±‚ï¼šè¾“å…¥å±‚å’Œè¾“å‡ºå±‚"},
                            {"q": "æƒé‡çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ", "a": "æ§åˆ¶è¾“å…¥ç‰¹å¾çš„é‡è¦æ€§"},
                        ],
                    },
                    {
                        "topic": "æ¿€æ´»å‡½æ•°",
                        "explanation": "æ¿€æ´»å‡½æ•°å¼•å…¥éçº¿æ€§ï¼Œä½¿ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å¤æ‚æ¨¡å¼ã€‚",
                        "example": "ReLU(x) = max(0, x)ï¼Œå½“ x=-2 æ—¶è¾“å‡º 0ï¼Œå½“ x=3 æ—¶è¾“å‡º 3ã€‚",
                        "code": "def relu(x):\n    return max(0, x)",
                        "challenge": ["ä¸ºä»€ä¹ˆçº¿æ€§æ¿€æ´»å‡½æ•°æ— æ³•è§£å†³å¤æ‚é—®é¢˜ï¼Ÿ"],
                        "self_check": [
                            {"q": "ReLU çš„å…¨ç§°æ˜¯ä»€ä¹ˆï¼Ÿ", "a": "Rectified Linear Unit"},
                        ],
                    },
                ],
            },
            {
                "chapter_title": "åå‘ä¼ æ’­ç®—æ³•",
                "chapter_summary": "æœ¬ç« è®²è§£å¦‚ä½•é€šè¿‡åå‘ä¼ æ’­è®­ç»ƒç¥ç»ç½‘ç»œã€‚",
                "sections": [
                    {
                        "topic": "æ¢¯åº¦ä¸‹é™",
                        "explanation": "æ¢¯åº¦ä¸‹é™é€šè¿‡è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦æ¥æ›´æ–°æƒé‡ã€‚",
                        "example": "æƒé‡æ›´æ–°ï¼šw_new = w_old - learning_rate * gradient",
                        "code": "w = w - 0.01 * gradient",
                        "self_check": [
                            {
                                "q": "å­¦ä¹ ç‡è¿‡å¤§ä¼šæ€æ ·ï¼Ÿ",
                                "a": "å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šæˆ–å‘æ•£",
                            },
                        ],
                    },
                ],
            },
        ],
        glossary={
            "æ„ŸçŸ¥æœº": "æœ€ç®€å•çš„ç¥ç»ç½‘ç»œå•å…ƒï¼Œåªæœ‰è¾“å…¥å±‚å’Œè¾“å‡ºå±‚",
            "æ¿€æ´»å‡½æ•°": "å¼•å…¥éçº¿æ€§çš„æ•°å­¦å‡½æ•°ï¼Œå¦‚ ReLUã€Sigmoid",
            "æ¢¯åº¦ä¸‹é™": "é€šè¿‡è®¡ç®—æ¢¯åº¦ä¼˜åŒ–æ¨¡å‹å‚æ•°çš„ç®—æ³•",
        },
    )


class TestDefaultModeStructure:
    """æµ‹è¯•é»˜è®¤æ¨¡å¼ï¼ˆCore+Appendixï¼‰çš„ç»“æ„å¥‘çº¦"""

    def test_required_headings_exist_and_ordered(self, minimal_knowledge_doc):
        """æµ‹è¯•å¿…éœ€çš„æ ‡é¢˜å­˜åœ¨ä¸”é¡ºåºæ­£ç¡®"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        # å¿…éœ€çš„æ ‡é¢˜ï¼ˆæŒ‰é¡ºåºï¼‰
        required_headings = [
            "# æµ‹è¯•æ ‡é¢˜ï¼šæ·±åº¦å­¦ä¹ åŸºç¡€",
            "## ğŸ“ å…³é”®ç»“è®º (Key Takeaways)",
            "## ğŸ” æ·±åº¦è§£æ (Deep Dive)",
            "## ğŸ“Œ è¦†ç›–æ¸…å• (Coverage Index)",
            "## ğŸ“ é™„å½• (Appendix)",
            "## ğŸ“– å…³é”®æœ¯è¯­è¡¨ (Glossary)",
        ]

        for heading in required_headings:
            assert heading in markdown, f"ç¼ºå°‘å¿…éœ€æ ‡é¢˜: {heading}"

        # éªŒè¯æ ‡é¢˜é¡ºåº
        positions = [markdown.find(h) for h in required_headings]
        assert positions == sorted(positions), "æ ‡é¢˜é¡ºåºä¸æ­£ç¡®"

    def test_no_challenge_blocks_in_default_mode(self, minimal_knowledge_doc):
        """æµ‹è¯•é»˜è®¤æ¨¡å¼ä¸‹æ²¡æœ‰æŒ‘æˆ˜å—"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        assert "**ğŸ§© æŒ‘æˆ˜" not in markdown, "é»˜è®¤æ¨¡å¼ä¸åº”åŒ…å«æŒ‘æˆ˜å—"
        assert "**ğŸ§©" not in markdown, "é»˜è®¤æ¨¡å¼ä¸åº”åŒ…å«ä»»ä½•æŒ‘æˆ˜æ ‡è®°"

    def test_no_per_section_self_check_in_default_mode(self, minimal_knowledge_doc):
        """æµ‹è¯•é»˜è®¤æ¨¡å¼ä¸‹æ²¡æœ‰æ¯èŠ‚è‡ªæµ‹å—"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        # ä¸åº”è¯¥æœ‰æ¯èŠ‚çš„è‡ªæµ‹å—
        assert "**âœ… è‡ªæµ‹ï¼ˆåšå®Œå†çœ‹ç­”æ¡ˆï¼‰**" not in markdown, (
            "é»˜è®¤æ¨¡å¼ä¸åº”åŒ…å«æ¯èŠ‚è‡ªæµ‹å—"
        )

    def test_chapter_level_self_check_exists(self, minimal_knowledge_doc):
        """æµ‹è¯•ç« èŠ‚çº§è‡ªæµ‹å­˜åœ¨ï¼ˆæ–°æ ¼å¼ï¼š### ğŸ“‹ ç¬¬1ç« è‡ªæµ‹ï¼‰"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        assert "### ğŸ“‹ ç¬¬1ç« è‡ªæµ‹" in markdown, (
            "é»˜è®¤æ¨¡å¼åº”åŒ…å«ç« èŠ‚çº§è‡ªæµ‹æ ‡é¢˜ï¼ˆæ ¼å¼ï¼š### ğŸ“‹ ç¬¬1ç« è‡ªæµ‹ï¼‰ï¼Œ"
            "è€Œéå½“å‰çš„ #### ğŸ“Œ æœ¬ç« è‡ªæµ‹ç­”æ¡ˆ"
        )

    def test_self_check_answers_immediately_after_questions(
        self, minimal_knowledge_doc
    ):
        """æµ‹è¯•è‡ªæµ‹ç­”æ¡ˆç´§è·Ÿåœ¨é—®é¢˜åé¢"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        # æŸ¥æ‰¾è‡ªæµ‹é—®é¢˜å’Œç­”æ¡ˆçš„ä½ç½®
        lines = markdown.split("\n")

        # åº”è¯¥èƒ½æ‰¾åˆ°é—®é¢˜å’Œç­”æ¡ˆåœ¨ç›¸é‚»åŒºåŸŸ
        found_question = False
        found_answer = False
        max_gap = 10  # é—®é¢˜å’Œç­”æ¡ˆä¹‹é—´æœ€å¤šé—´éš”10è¡Œ

        for i, line in enumerate(lines):
            if "Q1.1" in line or "Q1." in line:
                found_question = True
                # åœ¨æ¥ä¸‹æ¥çš„å‡ è¡Œå†…åº”è¯¥èƒ½æ‰¾åˆ°ç­”æ¡ˆ
                for j in range(i, min(i + max_gap, len(lines))):
                    if "ç­”æ¡ˆ" in lines[j] or "A1.1" in lines[j]:
                        found_answer = True
                        break
                break

        assert found_question, "åº”åŒ…å«è‡ªæµ‹é—®é¢˜"
        assert found_answer, "ç­”æ¡ˆåº”ç´§è·Ÿåœ¨é—®é¢˜åé¢"

    def test_answers_do_not_repeat_question_stems(self, minimal_knowledge_doc):
        """æµ‹è¯•ç­”æ¡ˆä¸é‡å¤é—®é¢˜é¢˜å¹²"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        lines = markdown.split("\n")

        # æŸ¥æ‰¾ç­”æ¡ˆè¡Œ
        for line in lines:
            if "ç­”æ¡ˆï¼š" in line or line.strip().startswith("A"):
                # ç­”æ¡ˆä¸åº”è¯¥åŒ…å«å®Œæ•´çš„é—®é¢˜é¢˜å¹²
                # ä¾‹å¦‚ï¼šä¸åº”è¯¥æ˜¯ "ç­”æ¡ˆï¼šæ„ŸçŸ¥æœºæœ‰å‡ å±‚ï¼Ÿä¸¤å±‚"
                # è€Œåº”è¯¥æ˜¯ "ç­”æ¡ˆï¼šä¸¤å±‚ï¼šè¾“å…¥å±‚å’Œè¾“å‡ºå±‚"

                # æ£€æŸ¥ç­”æ¡ˆä¸­æ˜¯å¦åŒ…å«é—®å·ï¼ˆè¡¨ç¤ºé‡å¤äº†é—®é¢˜ï¼‰
                answer_part = line.split("ç­”æ¡ˆï¼š")[-1] if "ç­”æ¡ˆï¼š" in line else line
                assert "ï¼Ÿ" not in answer_part, f"ç­”æ¡ˆä¸åº”é‡å¤é—®é¢˜é¢˜å¹²: {line}"

    def test_no_code_fences_in_main_content(self, minimal_knowledge_doc):
        """æµ‹è¯•ä¸»å†…å®¹åŒºæ²¡æœ‰ä»£ç å›´æ ï¼ˆåªåœ¨é™„å½•ä¸­ï¼‰"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        # åˆ†å‰²æ–‡æ¡£ï¼šæ‰¾åˆ°é™„å½•çš„ä½ç½®
        appendix_start = markdown.find("## ğŸ“ é™„å½• (Appendix)")

        if appendix_start == -1:
            pytest.fail("æœªæ‰¾åˆ°é™„å½•éƒ¨åˆ†")

        main_content = markdown[:appendix_start]
        appendix_content = markdown[appendix_start:]

        # ä¸»å†…å®¹ä¸åº”åŒ…å«ä»£ç å›´æ 
        assert "```" not in main_content, "ä¸»å†…å®¹åŒºä¸åº”åŒ…å«ä»£ç å›´æ "

        # é™„å½•åº”è¯¥åŒ…å«ä»£ç 
        assert "```" in appendix_content, "é™„å½•åº”åŒ…å«ä»£ç ç¤ºä¾‹"

    def test_coverage_index_generated_from_deep_dive(self, minimal_knowledge_doc):
        """æµ‹è¯•è¦†ç›–æ¸…å•ä» deep_dive ç”Ÿæˆ"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        # è¦†ç›–æ¸…å•åº”è¯¥åŒ…å«æ‰€æœ‰ç« èŠ‚å’Œä¸»é¢˜
        assert "## ğŸ“Œ è¦†ç›–æ¸…å• (Coverage Index)" in markdown

        # åº”è¯¥åˆ—å‡ºæ‰€æœ‰ä¸»é¢˜
        assert "æ„ŸçŸ¥æœºæ¨¡å‹" in markdown
        assert "æ¿€æ´»å‡½æ•°" in markdown
        assert "æ¢¯åº¦ä¸‹é™" in markdown

        # è¦†ç›–æ¸…å•åº”è¯¥åœ¨æ·±åº¦è§£æä¹‹åã€é™„å½•ä¹‹å‰
        deep_dive_pos = markdown.find("## ğŸ” æ·±åº¦è§£æ (Deep Dive)")
        coverage_pos = markdown.find("## ğŸ“Œ è¦†ç›–æ¸…å• (Coverage Index)")
        appendix_pos = markdown.find("## ğŸ“ é™„å½• (Appendix)")

        assert deep_dive_pos < coverage_pos < appendix_pos, "è¦†ç›–æ¸…å•ä½ç½®ä¸æ­£ç¡®"


class TestLegacyModeCompatibility:
    """æµ‹è¯•é—ç•™æ¨¡å¼çš„å‘åå…¼å®¹æ€§"""

    def test_legacy_mode_has_per_section_challenges(self, minimal_knowledge_doc):
        """æµ‹è¯•é—ç•™æ¨¡å¼ä¿ç•™æ¯èŠ‚æŒ‘æˆ˜å—"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="static")

        # é—ç•™æ¨¡å¼åº”è¯¥åŒ…å«æŒ‘æˆ˜å—
        assert "**ğŸ§© æŒ‘æˆ˜" in markdown, "é—ç•™æ¨¡å¼åº”åŒ…å«æŒ‘æˆ˜å—"

    def test_legacy_mode_has_per_section_self_check(self, minimal_knowledge_doc):
        """æµ‹è¯•é—ç•™æ¨¡å¼ä¿ç•™æ¯èŠ‚è‡ªæµ‹å—"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="static")

        # é—ç•™æ¨¡å¼åº”è¯¥åŒ…å«æ¯èŠ‚è‡ªæµ‹
        assert "**âœ… è‡ªæµ‹" in markdown, "é—ç•™æ¨¡å¼åº”åŒ…å«æ¯èŠ‚è‡ªæµ‹å—"

    def test_legacy_mode_has_code_in_main_content(self, minimal_knowledge_doc):
        """æµ‹è¯•é—ç•™æ¨¡å¼åœ¨ä¸»å†…å®¹ä¸­åŒ…å«ä»£ç """
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="static")

        # é—ç•™æ¨¡å¼åº”è¯¥åœ¨ä¸»å†…å®¹ä¸­åŒ…å«ä»£ç 
        deep_dive_start = markdown.find("## ğŸ” æ·±åº¦è§£æ (Deep Dive)")
        glossary_start = markdown.find("## ğŸ“– å…³é”®æœ¯è¯­è¡¨ (Glossary)")

        if deep_dive_start == -1 or glossary_start == -1:
            pytest.fail("æœªæ‰¾åˆ°æ·±åº¦è§£ææˆ–æœ¯è¯­è¡¨éƒ¨åˆ†")

        main_content = markdown[deep_dive_start:glossary_start]

        assert "```" in main_content, "é—ç•™æ¨¡å¼åº”åœ¨ä¸»å†…å®¹ä¸­åŒ…å«ä»£ç å›´æ "

    def test_legacy_mode_no_coverage_index(self, minimal_knowledge_doc):
        """æµ‹è¯•é—ç•™æ¨¡å¼æ²¡æœ‰è¦†ç›–æ¸…å•"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="static")

        # é—ç•™æ¨¡å¼ä¸åº”è¯¥æœ‰è¦†ç›–æ¸…å•
        assert "## ğŸ“Œ è¦†ç›–æ¸…å• (Coverage Index)" not in markdown, (
            "é—ç•™æ¨¡å¼ä¸åº”åŒ…å«è¦†ç›–æ¸…å•"
        )

    def test_legacy_mode_no_appendix(self, minimal_knowledge_doc):
        """æµ‹è¯•é—ç•™æ¨¡å¼æ²¡æœ‰é™„å½•"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="static")

        # é—ç•™æ¨¡å¼ä¸åº”è¯¥æœ‰é™„å½•
        assert "## ğŸ“ é™„å½• (Appendix)" not in markdown, "é—ç•™æ¨¡å¼ä¸åº”åŒ…å«é™„å½•"


class TestAnswerFormat:
    """æµ‹è¯•ç­”æ¡ˆæ ¼å¼è§„èŒƒ"""

    def test_answer_format_concise(self, minimal_knowledge_doc):
        """æµ‹è¯•ç­”æ¡ˆæ ¼å¼ç®€æ´ï¼ˆä¸é‡å¤é—®é¢˜ï¼‰"""
        markdown = minimal_knowledge_doc.to_markdown(self_check_mode="default")

        lines = markdown.split("\n")

        for i, line in enumerate(lines):
            if "ç­”æ¡ˆï¼š" in line:
                # ç­”æ¡ˆåº”è¯¥ç›´æ¥ç»™å‡ºï¼Œä¸é‡å¤é—®é¢˜
                # æ­£ç¡®æ ¼å¼: "ç­”æ¡ˆï¼šä¸¤å±‚ï¼šè¾“å…¥å±‚å’Œè¾“å‡ºå±‚"
                # é”™è¯¯æ ¼å¼: "ç­”æ¡ˆï¼šæ„ŸçŸ¥æœºæœ‰å‡ å±‚ï¼Ÿç­”æ¡ˆæ˜¯ä¸¤å±‚"

                answer_text = line.split("ç­”æ¡ˆï¼š", 1)[-1].strip()

                # ç­”æ¡ˆä¸åº”è¯¥ä»¥é—®å·å¼€å¤´æˆ–åŒ…å«é—®å·
                assert not answer_text.startswith("æ„ŸçŸ¥æœº"), (
                    f"ç­”æ¡ˆé‡å¤äº†é—®é¢˜ä¸»è¯­: {line}"
                )
                assert "ï¼Ÿ" not in answer_text, (
                    f"ç­”æ¡ˆåŒ…å«é—®å·ï¼ˆå¯èƒ½é‡å¤äº†é—®é¢˜ï¼‰: {line}"
                )


class TestEdgeCases:
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""

    def test_empty_glossary_handled(self):
        """æµ‹è¯•ç©ºæœ¯è¯­è¡¨çš„å¤„ç†"""
        doc = KnowledgeDocument(
            title="æµ‹è¯•",
            one_sentence_summary="æµ‹è¯•",
            key_takeaways=["æµ‹è¯•"],
            deep_dive=[
                {
                    "chapter_title": "æµ‹è¯•ç« èŠ‚",
                    "sections": [
                        {
                            "topic": "æµ‹è¯•ä¸»é¢˜",
                            "explanation": "æµ‹è¯•è§£é‡Š",
                        }
                    ],
                }
            ],
            glossary={},  # ç©ºæœ¯è¯­è¡¨
        )

        markdown = doc.to_markdown(self_check_mode="default")

        # ç©ºæœ¯è¯­è¡¨ä¸åº”è¯¥æ¸²æŸ“æœ¯è¯­è¡¨éƒ¨åˆ†
        # æˆ–è€…æ¸²æŸ“ä½†ä¸ºç©º
        if "## ğŸ“– å…³é”®æœ¯è¯­è¡¨ (Glossary)" in markdown:
            # å¦‚æœæ¸²æŸ“äº†ï¼Œåº”è¯¥æ²¡æœ‰æœ¯è¯­æ¡ç›®
            glossary_section = markdown.split("## ğŸ“– å…³é”®æœ¯è¯­è¡¨ (Glossary)")[-1]
            next_section = (
                glossary_section.split("##")[0]
                if "##" in glossary_section
                else glossary_section
            )
            assert "**" not in next_section or next_section.strip() == "", (
                "ç©ºæœ¯è¯­è¡¨ä¸åº”æœ‰å†…å®¹"
            )

    def test_section_without_self_check(self):
        """æµ‹è¯•æ²¡æœ‰è‡ªæµ‹é¢˜çš„ç« èŠ‚"""
        doc = KnowledgeDocument(
            title="æµ‹è¯•",
            one_sentence_summary="æµ‹è¯•",
            key_takeaways=["æµ‹è¯•"],
            deep_dive=[
                {
                    "chapter_title": "æµ‹è¯•ç« èŠ‚",
                    "sections": [
                        {
                            "topic": "æµ‹è¯•ä¸»é¢˜",
                            "explanation": "æµ‹è¯•è§£é‡Š",
                            # æ²¡æœ‰ self_check å­—æ®µ
                        }
                    ],
                }
            ],
            glossary={},
        )

        markdown = doc.to_markdown(self_check_mode="default")

        # åº”è¯¥èƒ½æ­£å¸¸æ¸²æŸ“ï¼Œä¸ä¼šå´©æºƒ
        assert "æµ‹è¯•ä¸»é¢˜" in markdown
