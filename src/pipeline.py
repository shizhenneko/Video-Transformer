"""
ä¸»æµç¨‹ç¼–æ’å™¨

è´Ÿè´£åè°ƒè§†é¢‘ä¸‹è½½ã€åˆ†æã€æ ¡éªŒã€å›¾åƒç”Ÿæˆå’Œå®¡æ ¸çš„å®Œæ•´æµç¨‹
"""

from __future__ import annotations

import logging
import re
import time
from pathlib import Path
from typing import Any

import requests

from analyzer.content_analyzer import ContentAnalyzer
from auditor.quality_auditor import QualityAuditor
from downloader.video_downloader import VideoDownloader
from models import BatchResult, ProcessResult
from utils.counter import APICounter, APILimitExceeded
from utils.gemini_throttle import GeminiThrottle
from utils.progress_tracker import ProgressTracker
from validator.consistency_validator import ConsistencyValidator
from visualizer.image_generator import ImageGenerator


class VideoPipeline:
    """è§†é¢‘å¤„ç†æµç¨‹ç¼–æ’å™¨"""

    def __init__(
        self,
        config: dict[str, Any],
        logger: logging.Logger,
        api_counter: APICounter,
        progress_tracker: ProgressTracker | None = None,
    ):
        """
        åˆå§‹åŒ–æµç¨‹ç¼–æ’å™¨

        Args:
            config: ç³»ç»Ÿé…ç½®
            logger: æ—¥å¿—è®°å½•å™¨
            api_counter: API è°ƒç”¨è®¡æ•°å™¨
            progress_tracker: è¿›åº¦è¿½è¸ªå™¨(å¯é€‰)
        """
        self.config = config
        self.logger = logger
        self.api_counter = api_counter
        self.progress_tracker = progress_tracker

        self.progress_tracker = progress_tracker

        # åˆå§‹åŒ–å„æ¨¡å—
        self.downloader = VideoDownloader(config, logger)

        self.validator = ConsistencyValidator(
            config=config,
            api_counter=api_counter,
            logger=logger,
        )

        self.generator = ImageGenerator(
            config=config,
            logger=logger,
        )

        self.validator = ConsistencyValidator(
            config=config,
            api_counter=api_counter,
            logger=logger,
        )

        self.generator = ImageGenerator(
            config=config,
            logger=logger,
        )



        # è¾“å‡ºç›®å½•
        self.output_dir = Path(config["system"]["output_dir"])
        self.doc_dir = self.output_dir / "documents"
        self.blueprint_dir = self.output_dir / "blueprints"

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.doc_dir.mkdir(parents=True, exist_ok=True)
        self.blueprint_dir.mkdir(parents=True, exist_ok=True)

        # æ ¡éªŒé…ç½®
        validator_config = config.get("validator", {})
        self.validation_threshold = validator_config.get("threshold", 75.0)
        self.max_validation_rounds = validator_config.get("max_rounds", 3)

        self.logger.info("VideoPipeline åˆå§‹åŒ–å®Œæˆ")

    def process_single_video(self, url: str) -> ProcessResult:
        """
        å¤„ç†å•ä¸ªè§†é¢‘

        Args:
            url: è§†é¢‘ URL

        Returns:
            ProcessResult: å¤„ç†ç»“æœ
        """
        start_time = time.time()
        video_id = self._extract_video_id(url)

        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_id}")
        self.logger.info(f"URL: {url}")
        self.logger.info(f"{'='*60}")

        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        if self.progress_tracker and self.progress_tracker.is_processed(video_id):
            self.logger.info(f"è§†é¢‘ {video_id} å·²å¤„ç†,è·³è¿‡")
            return ProcessResult(
                video_id=video_id,
                url=url,
                success=True,
                error_message="å·²å¤„ç†(è·³è¿‡)",
                processing_time=0.0,
            )

        api_calls_start = self.api_counter.current_count

        # 1. åˆ†é…å½“å‰è§†é¢‘ä¸“ç”¨ Key
        current_api_key = self._allocate_gemini_key()
        
        # 2. åˆ›å»ºå…±äº«é™æµå™¨ (åŒä¸€ä¸ªè§†é¢‘ä»»åŠ¡å†…æ‰€æœ‰ Gemini è°ƒç”¨å…±äº«é™é€Ÿ)
        analyzer_config = self.config.get("analyzer", {})
        throttle = GeminiThrottle(
            min_interval=analyzer_config.get("min_call_interval", 4.0),
            max_retries=analyzer_config.get("retry_times", 10),
            max_total_wait=analyzer_config.get("max_retry_wait", 600.0),
            logger=self.logger,
        )
        
        # 3. å®ä¾‹åŒ–ç»„ä»¶ (ä½¿ç”¨å½“å‰åˆ†é…çš„ Key + å…±äº«é™æµå™¨)
        analyzer = ContentAnalyzer(
            config=self.config,
            api_counter=self.api_counter,
            logger=self.logger,
            api_key=current_api_key,
            throttle=throttle,
        )
        auditor = QualityAuditor(
            config=self.config,
            api_counter=self.api_counter,
            logger=self.logger,
            api_key=current_api_key,
            throttle=throttle,
        )

        try:
            # æ­¥éª¤ 1: ä¸‹è½½è§†é¢‘
            self.logger.info("\n[1/5] ä¸‹è½½è§†é¢‘...")
            video_path = self.downloader.download_video(url)
            if not video_path:
                raise RuntimeError("è§†é¢‘ä¸‹è½½å¤±è´¥")
            self.logger.info(f"âœ… è§†é¢‘å·²ä¸‹è½½: {video_path}")

            # æ­¥éª¤ 2: å†…å®¹åˆ†æ
            self.logger.info("\n[2/5] åˆ†æè§†é¢‘å†…å®¹...")
            analysis_result = analyzer.analyze_video(video_path)
            self.logger.info(
                f"âœ… å†…å®¹åˆ†æå®Œæˆ (çŸ¥è¯†ç‚¹: {len(analysis_result.knowledge_doc.deep_dive)})"
            )

            # æ­¥éª¤ 3: æ ¡éªŒä¸æ”¹å†™å¾ªç¯
            self.logger.info("\n[3/5] æ ¡éªŒçŸ¥è¯†è“å›¾ Visual Schema...")
            final_structure = self._validation_loop(
                analysis_result.knowledge_doc.visual_schema, analysis_result.knowledge_doc.to_markdown()
            )

            # æ­¥éª¤ 4: ç”Ÿæˆå›¾ç‰‡
            image_data = None
            audit_result = None
            
            if final_structure:
                self.logger.info("\n[4/5] ç”ŸæˆçŸ¥è¯†è“å›¾å›¾ç‰‡...")
                try:
                    image_data = self.generator.generate_blueprint(final_structure)
                    if image_data:
                        self.logger.info(f"âœ… å›¾ç‰‡ç”Ÿæˆå®Œæˆ ({len(image_data)} bytes)")

                        # æ­¥éª¤ 5: å®¡æ ¸å›¾ç‰‡
                        self.logger.info("\n[5/5] å®¡æ ¸å›¾ç‰‡è´¨é‡...")
                        blueprint_path_temp = self.output_dir / "temp" / f"{video_id}_temp.png"
                        blueprint_path_temp.parent.mkdir(parents=True, exist_ok=True)
                        
                        try:
                            self.generator.save_image(image_data, blueprint_path_temp)

                            audit_result = auditor.audit_image(
                                image_path=blueprint_path_temp,
                                knowledge_doc_content=analysis_result.knowledge_doc.to_markdown(),
                            )
                            
                            if audit_result.passed:
                                self.logger.info(f"âœ… å®¡æ ¸é€šè¿‡ (åˆ†æ•°: {audit_result.score:.1f})")
                            else:
                                self.logger.warning(
                                    f"âŒ å®¡æ ¸æœªé€šè¿‡ (åˆ†æ•°: {audit_result.score:.1f} < {auditor.threshold})\n"
                                    f"åé¦ˆ: {audit_result.feedback}"
                                )
                                self.logger.info("ä¸¢å¼ƒè´¨é‡ä¸ä½³çš„å›¾ç‰‡")
                                image_data = None
                                audit_result = None # Clear result so it doesn't show up as success in stats? or keep it?
                                # Keep explicit audit result for logging/stats if needed, but here we just need to ensure image is not saved.
                                
                        except Exception as e:
                            self.logger.warning(f"âš ï¸ å›¾ç‰‡å®¡æ ¸è¿‡ç¨‹å‡ºé”™ (å·²ä¿ç•™åŸå›¾)ï¼Œè·³è¿‡å®¡æ ¸: {e}") 
                            # If audit fails due to error (not quality), we currently keep the image.
                            # Is this desired? "Kimi çœ‹åˆ°è´¨é‡ä¸ä½³çš„å›¾åº”è¯¥ç›´æ¥æ‹’ç»".
                            # If audit crashes, we might want to keep it or discard it. The prompt implies "quality poor".
                            # So exception means we don't know the quality. Defaulting to keep is safer for "errors", 
                            # but for "quality failure" we discard.
                        
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if blueprint_path_temp.exists():
                           blueprint_path_temp.unlink()

                    else:
                        self.logger.warning("âŒ å›¾ç‰‡ç”Ÿæˆè¿”å›ç©ºæ•°æ®")
                
                except Exception as e:
                     self.logger.error(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
                     image_data = None
            else:
                self.logger.warning("âš ï¸ Visual Schema ä¸ºç©ºï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆä¸å®¡æ ¸")

            # ä¿å­˜æœ€ç»ˆè¾“å‡º
            image_relative_path = f"../blueprints/{video_id}_mind_map.png" if image_data else None
            
            doc_path, blueprint_path = self._save_outputs(
                video_id=video_id,
                document_content=analyzer.generate_report(analysis_result, image_relative_path),
                image_data=image_data,
            )

            # è®¡ç®— API è°ƒç”¨æ¬¡æ•°
            api_calls_used = self.api_counter.current_count - api_calls_start
            processing_time = time.time() - start_time

            # æ ‡è®°ä¸ºå·²å¤„ç†
            if self.progress_tracker:
                self.progress_tracker.mark_processed(video_id)

            result = ProcessResult(
                video_id=video_id,
                url=url,
                success=True,
                document_path=str(doc_path),
                blueprint_path=str(blueprint_path) if blueprint_path else None,
                api_calls_used=api_calls_used,
                processing_time=processing_time,
                audit_score=audit_result.score if audit_result else 0.0,
            )

            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"âœ… å¤„ç†æˆåŠŸ: {video_id}")
            if not blueprint_path:
                self.logger.info("âš ï¸ æ³¨æ„: æœªç”ŸæˆçŸ¥è¯†è“å›¾å›¾ç‰‡")
            self.logger.info(f"API è°ƒç”¨: {api_calls_used}")
            self.logger.info(f"è€—æ—¶: {processing_time:.1f}s")
            self.logger.info(f"{'='*60}\n")

            return result

        except APILimitExceeded as e:
            self.logger.error(f"âŒ API è°ƒç”¨æ¬¡æ•°è¶…é™: {e}")
            processing_time = time.time() - start_time
            return ProcessResult(
                video_id=video_id,
                url=url,
                success=False,
                error_message=f"API è°ƒç”¨è¶…é™: {e}",
                processing_time=processing_time,
            )

        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}", exc_info=True)
            processing_time = time.time() - start_time

            # æ ‡è®°ä¸ºå¤±è´¥
            if self.progress_tracker:
                self.progress_tracker.mark_failed(video_id, str(e))

            return ProcessResult(
                video_id=video_id,
                url=url,
                success=False,
                error_message=str(e),
                processing_time=processing_time,
            )

    def process_batch(self, urls: list[str]) -> BatchResult:
        """
        æ‰¹é‡å¤„ç†è§†é¢‘

        Args:
            urls: è§†é¢‘ URL åˆ—è¡¨

        Returns:
            BatchResult: æ‰¹é‡å¤„ç†ç»“æœ
        """
        total = len(urls)
        self.logger.info(f"\nå¼€å§‹æ‰¹é‡å¤„ç† {total} ä¸ªè§†é¢‘")

        result = BatchResult(total=total, successful=0, failed=0)

        for idx, url in enumerate(urls, 1):
            self.logger.info(f"\nå¤„ç†è¿›åº¦: {idx}/{total}")

            # æ£€æŸ¥ API è°ƒç”¨æ¬¡æ•°
            if not self.api_counter.can_call():
                self.logger.warning(
                    f"API è°ƒç”¨æ¬¡æ•°å·²è¾¾ä¸Šé™,ç»ˆæ­¢æ‰¹é‡å¤„ç† (å·²å¤„ç† {idx-1}/{total})"
                )
                break

            # å¤„ç†å•ä¸ªè§†é¢‘
            video_result = self.process_single_video(url)
            result.add_result(video_result)

            if video_result.success:
                result.successful += 1
            else:
                result.failed += 1

        self.logger.info(f"\næ‰¹é‡å¤„ç†å®Œæˆ: {result}")
        return result

    def _validation_loop(
        self, initial_structure: str, knowledge_content: str
    ) -> str:
        """
        æ ¡éªŒ-æ”¹å†™å¾ªç¯

        Args:
            initial_structure: åˆå§‹ Visual Schema
            knowledge_content: çŸ¥è¯†ç¬”è®°å†…å®¹

        Returns:
            æœ€ç»ˆçš„ Visual Schema
        """
        current_structure = initial_structure
        if not current_structure:
             self.logger.warning("Visual Schema ä¸ºç©ºï¼Œè·³è¿‡æ ¡éªŒ")
             return ""

        for round_num in range(1, self.max_validation_rounds + 1):
            self.logger.info(f"  ç¬¬ {round_num} è½®æ ¡éªŒ...")

            try:
                validation_result = self.validator.validate(
                    mind_map_structure=current_structure,
                    knowledge_doc_content=knowledge_content,
                )

                self.logger.info(
                    f"  æ ¡éªŒå¾—åˆ†: {validation_result.total_score:.1f}/100"
                )

                if validation_result.passed:
                    self.logger.info(f"  âœ… æ ¡éªŒé€šè¿‡!")
                    return current_structure

                else:
                    self.logger.warning(
                        f"  âš ï¸ æ ¡éªŒæœªé€šè¿‡ (é˜ˆå€¼: {self.validation_threshold})"
                    )
                    self.logger.info(f"  åé¦ˆ: {validation_result.feedback}")

                    if round_num < self.max_validation_rounds:
                        self.logger.info(f"  å°è¯•æ”¹å†™...")
                        current_structure = analyzer.rewrite_visual_schema(
                            original_structure=current_structure,
                            feedback=validation_result.feedback,
                        )
                        self.logger.info(f"  æ”¹å†™å®Œæˆ,è¿›å…¥ä¸‹ä¸€è½®æ ¡éªŒ")
                    else:
                        self.logger.warning(
                            f"  å·²è¾¾æœ€å¤§æ ¡éªŒè½®æ¬¡ ({self.max_validation_rounds}),ä½¿ç”¨å½“å‰ç»“æ„"
                        )

            except Exception as e:
                self.logger.error(f"  æ ¡éªŒå¤±è´¥: {e}")
                break

        return current_structure

    def _save_outputs(
        self, video_id: str, document_content: str, image_data: bytes | None
    ) -> tuple[Path, Path | None]:
        """
        ä¿å­˜è¾“å‡ºæ–‡ä»¶

        Args:
            video_id: è§†é¢‘ ID
            document_content: æ–‡æ¡£å†…å®¹
            image_data: å›¾ç‰‡æ•°æ® (å¯é€‰)

        Returns:
            (æ–‡æ¡£è·¯å¾„, å›¾ç‰‡è·¯å¾„)
        """
        # æ–‡æ¡£è·¯å¾„: {video_id}_knowledge_note.md
        doc_path = self.doc_dir / f"{video_id}_knowledge_note.md"
        with open(doc_path, "w", encoding="utf-8") as f:
            f.write(document_content)
        self.logger.info(f"ğŸ“„ æ–‡æ¡£å·²ä¿å­˜: {doc_path}")

        blueprint_path = None
        if image_data:
            # å›¾ç‰‡è·¯å¾„: {video_id}_mind_map.png
            blueprint_path = self.blueprint_dir / f"{video_id}_mind_map.png"
            self.generator.save_image(image_data, blueprint_path)
            self.logger.info(f"ğŸ–¼ï¸  å›¾ç‰‡å·²ä¿å­˜: {blueprint_path}")

        return doc_path, blueprint_path

    def _extract_video_id(self, url: str) -> str:
        """
        ä» URL æå–è§†é¢‘ ID (æ”¯æŒåˆ†é›†)

        Args:
            url: è§†é¢‘ URL

        Returns:
            è§†é¢‘ ID (å¦‚æœåŒ…å«åˆ†é›† p å‚æ•°,ä¼šé™„åŠ  _p{N})
        """
        video_id = None
        
        # Bilibili BV å·åŒ¹é…
        bv_match = re.search(r"BV[a-zA-Z0-9]+", url)
        if bv_match:
            video_id = bv_match.group(0)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†é›†å‚æ•° (p=X)
            p_match = re.search(r"[?&]p=(\d+)", url)
            if p_match:
                p_num = p_match.group(1)
                video_id = f"{video_id}_p{p_num}"

        # YouTube è§†é¢‘ ID åŒ¹é…
        if not video_id:
            yt_match = re.search(r"(?:v=|/)([a-zA-Z0-9_-]{11})", url)
            if yt_match:
                video_id = yt_match.group(1)

        # å…¶ä»–æƒ…å†µ,ä½¿ç”¨ URL çš„å“ˆå¸Œå€¼
        if not video_id:
            import hashlib
            video_id = hashlib.md5(url.encode()).hexdigest()[:12]
            
        return video_id

    def _allocate_gemini_key(self) -> str | None:
        """
        ä¸ºæ•´ä¸ª Pipeline åˆ†é…ä¸€ä¸ªç»Ÿä¸€çš„ Gemini API Key

        Returns:
            str | None: åˆ†é…åˆ°çš„ API Key,å¦‚æœæœªé…ç½®ä¸”å·æ± ä¸å¯ç”¨åˆ™è¿”å› None
        """
        # 1. ä¼˜å…ˆä»é…ç½®è¯»å–
        api_keys = self.config.get("api_keys", {})
        fixed_key = api_keys.get("gemini")
        if fixed_key:
            self.logger.info("ä»é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨å›ºå®š Gemini API Key")
            return fixed_key

        # 2. ä»ä»£ç†å·æ± åˆ†é…
        proxy_config = self.config.get("proxy", {})
        base_url = proxy_config.get("base_url", "http://localhost:8000")
        timeout = proxy_config.get("timeout", 10)

        self.logger.info(f"å°è¯•ä»ä»£ç†å·æ± åˆ†é…ç»Ÿä¸€ Gemini API Key ({base_url})...")
        url = f"{base_url.rstrip('/')}/sdk/allocate-key"

        try:
            resp = requests.post(url, timeout=timeout)
            if resp.status_code == 200:
                data = resp.json()
                key_id = data.get("key_id", "unknown")
                api_key = data.get("api_key")
                self.logger.info(f"âœ… æˆåŠŸä»å·æ± åˆ†é…ç»Ÿä¸€ Key: {key_id}")
                return api_key
            elif resp.status_code == 503:
                self.logger.warning("âš ï¸ å·æ± æ‰€æœ‰ Key å·²è€—å°½")
            else:
                self.logger.warning(
                    f"âš ï¸ å·æ± åˆ†é…å¤±è´¥ (HTTP {resp.status_code}): {resp.text}"
                )
        except Exception as e:
            self.logger.warning(f"âš ï¸ æ— æ³•è¿æ¥å·æ± è¿›è¡Œç»Ÿä¸€åˆ†å‘: {e}")

        return None
